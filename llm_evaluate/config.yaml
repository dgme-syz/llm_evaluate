data:
  name: math_train      
  data_path: /home/nfs06/shenyz/data/SimpleRL/hard/train_processed.parquet
  subset_name: null
  split: train
  num_samples: 512
  builder: parquet

evaluate:
  val_size: 1024
  num_proc: null
  metrics:
    - union_math_accuracy
  eval_func: base
  merge_strategy: pass

use_server: false

# /home/nfs05/shenyz/verl/checkpoints/verl_grpo/Qwen2.5-1.5B+n_7+Qwen3-8B+256+gpus_8/global_step_160/actor/huggingface
# /home/nfs05/shenyz/verl/checkpoints/verl_grpo/Qwen2.5-1.5B+GRPO+256+gpus_4/global_step_460/actor/huggingface
# /home/nfs06/shenyz/models/Qwen2.5-1.5B
llm:
  model: /home/nfs05/shenyz/verl/checkpoints/verl_grpo/Qwen2.5-1.5B+GRPO+256+gpus_4/global_step_300/actor/huggingface
  tokenizer: /home/nfs05/shenyz/verl/checkpoints/verl_grpo/Qwen2.5-1.5B+GRPO+256+gpus_4/global_step_300/actor/huggingface
  trust_remote_code: true
  dtype: bfloat16
  gpu_memory_utilization: 0.7
  tensor_parallel_size: 2
  seed: 42
  

server: {}

sample_params:
  offline:
    temperature: 1.0 #0.0
    max_tokens: 4096
    # top_p: 0.95 # 1.0
    # top_k: 20 # -1
    # repetition_penalty: 1.1 # 1
    n: 8

  online: {}


save_outputs: true # save format: jsonl
outputs_dir: ./outputs/1/rollout

exp_name_prefix: "__without_steps__"

hydra:
  run:
    dir: ./outputs/1/rollout

# simple rl greedy decode 0.57
# simple rl greedy 0.6 t 0.57